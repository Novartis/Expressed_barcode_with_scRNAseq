{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scAnalysis as scrna\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import scvelo as scv\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "scv.__version__\n",
    "scv.settings.presenter_view = True  # set max width size for presenter view\n",
    "scv.settings.set_figure_params('scvelo')  # for beautified visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = 'final_anndatas/MGH707.h5ad'#HCC4006.h5ad'#'HCC4006.h5ad'#\n",
    "cellline='MGH707'\n",
    "\n",
    "\n",
    "adata = sc.read(results_file)\n",
    "\n",
    "#df=scrna.andata2df(adata)\n",
    "#df=df[['Barcode','cloneid','louvain','timepoint']]\n",
    "#df.to_csv('to_josh/clone2louvainMGH707.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(dfin,features,Npca=10,number_genes=[],zscore=True):\n",
    "    #number_genes is the number of genes used to compute PCA, ordered bu std\n",
    "    \n",
    "    \n",
    "    \n",
    "    if number_genes==[]:\n",
    "        features2=features\n",
    "    else:\n",
    "        number_genes=min(number_genes,len(features))\n",
    "        df=dfin.copy()\n",
    "        df.loc['stds',:]=[0]*len(df.columns)\n",
    "        df.loc['stds',features] = df.loc[:,features].std(axis=0,ddof=0)/df.loc[:,features].mean(axis=0)\n",
    "        df=df.sort_values('stds',axis=1,ascending=False)\n",
    "        features2 = df.columns[0:number_genes]\n",
    "        \n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "\n",
    "    \n",
    "    #Compte actual PCs using all samples\n",
    "    print('Computing PCs...')\n",
    "    X = dfin.loc[:,features2].dropna()\n",
    "    if zscore:\n",
    "        for col in X.columns:\n",
    "            X[col] = (X[col] - X[col].mean())/X[col].std(ddof=0)\n",
    "    X=X.fillna(0)\n",
    "    pca = PCA(n_components=Npca)\n",
    "    PCs = pca.fit_transform(X)\n",
    "    perc = 100*pca.explained_variance_ratio_.sum()\n",
    "    print('Done!')\n",
    "\n",
    "    print('We use '+str(Npca)+' components to explain '+str(perc)+'% of the variability')\n",
    "\n",
    "    #create DF with PCA results \n",
    "    dfout = dfin.copy()\n",
    "    pclist = []\n",
    "    for i in range(PCs.shape[1]):\n",
    "        dfout.loc[:,'PC'+str(i+1)] = PCs[:,i]\n",
    "        pclist.append('PC'+str(i+1))\n",
    "\n",
    "    print(pca.explained_variance_ratio_)  \n",
    "    print(pca.explained_variance_ratio_.sum())\n",
    "    \n",
    "    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "    loads = pd.DataFrame(loadings,index=features2,columns = pclist)\n",
    "    loads =loads.sort_values('PC1',ascending=False)\n",
    "    \n",
    "    return dfout, loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering='louvain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata, clustering, method='t-test')\n",
    "p=sc.pl.rank_genes_groups_dotplot(adata, n_genes=4)\n",
    "\n",
    "#extract cluster order from dendogram and use it to create a graded colormap. \n",
    "#Then use that colormap to color the clusters in the barplots, so more similar ones have similar colors\n",
    "order=adata.uns['dendrogram_'+clustering]['categories_ordered']\n",
    "\n",
    "from matplotlib import cm\n",
    "colors = [cm.viridis(x) for x in np.linspace(0, 1, len(order))]\n",
    "colors_dict={order[i]:colors[i] for i in range(len(order))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result =adata.uns['rank_genes_groups']\n",
    "\n",
    "# sc.pl.rank_genes_groups(andataaux, n_genes=30)\n",
    "groups = result['names'].dtype.names\n",
    "df = pd.DataFrame(columns=groups)#{key: result[key][group] for group in groups for key in ['names', 'scores']})\n",
    "\n",
    "for c in df.columns:\n",
    "    df[c]=result['names'][c]\n",
    "    \n",
    "df=df.head(50)\n",
    "df.to_csv('figuresNEW/'+cellline+'/DEgenesLouvain'+cellline+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DE genes time 14day\n",
    "\n",
    "adataaux=adata[adata.obs['timepoint']=='14day']\n",
    "\n",
    "df=scrna.andata2df(adataaux)\n",
    "df=df[['louvain','Barcode']].groupby('louvain').count()\n",
    "df=df.loc[df['Barcode']>1]\n",
    "ids=df.index.tolist()\n",
    "adataaux=adataaux[np.isin(adataaux.obs['louvain'],ids)]\n",
    "\n",
    "sc.tl.rank_genes_groups(adataaux, clustering, method='t-test')\n",
    "sc.tl.dendrogram(adataaux,groupby='louvain')\n",
    "p=sc.pl.rank_genes_groups_dotplot(adataaux, n_genes=4)\n",
    "\n",
    "result =adataaux.uns['rank_genes_groups']\n",
    "\n",
    "# sc.pl.rank_genes_groups(andataaux, n_genes=30)\n",
    "groups = result['names'].dtype.names\n",
    "df = pd.DataFrame(columns=groups)#{key: result[key][group] for group in groups for key in ['names', 'scores']})\n",
    "\n",
    "for c in df.columns:\n",
    "    df[c]=result['names'][c]\n",
    "    \n",
    "df=df.head(50)\n",
    "df.to_csv('figuresNEW/'+cellline+'/DEgenesLouvain'+cellline+'_14day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cloneid\n",
    "df=scrna.andata2df(adata)\n",
    "\n",
    "gbdf=df[['Barcode',clustering,'cloneid']].groupby([clustering,'cloneid']).count()\n",
    "gbdf=gbdf.reset_index()\n",
    "gbdf=gbdf.pivot(index=clustering, columns='cloneid', values='Barcode')\n",
    "\n",
    "#discard barcodes with no asigned clone\n",
    "gbdf=gbdf[[i for i in gbdf.columns if '-' not in i]]\n",
    "\n",
    "#discard clones with no asigned barcodes\n",
    "gbdf=gbdf[[c for c in gbdf.columns if gbdf[c].sum()>0]]\n",
    "\n",
    "#discard louvains with no barcodes in them\n",
    "gbdf=gbdf.loc[[c for c in gbdf.index if gbdf.loc[c].sum()>0]]\n",
    "\n",
    "\n",
    "#normalize by total number of clones\n",
    "gbdfraw=gbdf.copy()\n",
    "gbdf=gbdf/gbdf.sum()\n",
    "#gbdf=gbdf.dropna(axis=1)\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "minnumbercells=40\n",
    "\n",
    "dfin=gbdfraw.copy()\n",
    "dfin.loc['sum']=dfin.sum()\n",
    "dfin=dfin.sort_values('sum',ascending=False,axis=1)\n",
    "sorted_clones=dfin.columns\n",
    "dfin=dfin[[c for c in dfin.columns if dfin.loc['sum',c]>minnumbercells]]\n",
    "df=dfin/dfin.loc['sum']\n",
    "\n",
    "sorted_clones_filtered=dfin.columns\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(0.3*len(df.columns), 5))\n",
    "# The position of the bars on the x-axis\n",
    "r = df.columns\n",
    "\n",
    "# Names of group and bar width\n",
    "names = df.columns\n",
    "barWidth = 1\n",
    "\n",
    "yold=df.loc[df.index[0]]*0\n",
    "for c in order:#[c for c in df.index if 'sum' not in c]:\n",
    "    y=df.loc[c]\n",
    "    ax.bar(r, y, bottom=yold, edgecolor='white', color=colors_dict[c],width=barWidth,label=c)\n",
    "    yold=yold+y.copy()\n",
    "    \n",
    "    \n",
    "# Custom X axis\n",
    "ax.set_xticks(r)\n",
    "ax.set_xlabel(\"clone id\")\n",
    "ax.set_xticklabels(names.tolist(), rotation = 90)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.15, 0.5))\n",
    "ax.set_ylabel('proportion of cells')\n",
    "\n",
    "ax2 = ax.twinx() \n",
    "ax2.plot(r,dfin.loc['sum'],'lightgray',linewidth=3)\n",
    "ax2.set_ylabel('number fo cells',color='gray') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clones_to_use = sorted_clones_filtered\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(13,10),sharex=True,sharey=True)\n",
    "axs=axs.ravel()\n",
    "k=0\n",
    "dfin=scrna.andata2df(adata)\n",
    "for t in adata.obs['timepoint'].unique():\n",
    "    ax=axs[k]\n",
    "    \n",
    "    df2=dfin.loc[dfin['timepoint']==t]\n",
    "\n",
    "    gbdf=df2[['Barcode',clustering,'cloneid']].groupby([clustering,'cloneid']).count()\n",
    "    gbdf=gbdf.reset_index()\n",
    "    gbdf=gbdf.pivot(index=clustering, columns='cloneid', values='Barcode')\n",
    "\n",
    "    #discard barcodes with no asigned clone\n",
    "    gbdf=gbdf[[i for i in gbdf.columns if '-' not in i]]\n",
    "\n",
    "    #discard clones with no asigned barcodes\n",
    "    #gbdf=gbdf[[c for c in gbdf.columns if gbdf[c].sum()>0]]\n",
    "\n",
    "    #discard louvains with no barcodes in them\n",
    "    #gbdf=gbdf.loc[[c for c in gbdf.index if gbdf.loc[c].sum()>0]]\n",
    "\n",
    "    #sort uisng previous data\n",
    "    gbdf=gbdf[clones_to_use]\n",
    "    \n",
    "    #normalize by total number of clones\n",
    "    gbdfraw=gbdf.copy()\n",
    "    gbdf=gbdf/gbdf.sum()\n",
    "    \n",
    "    \n",
    "    dfin2=gbdfraw.copy()\n",
    "    dfin2.loc['sum']=dfin2.sum()\n",
    "    #dfin2=dfin2[[c for c in dfin2.columns if dfin2.loc['sum',c]>5]]\n",
    "    df=dfin2/dfin2.loc['sum']\n",
    "\n",
    "    # The position of the bars on the x-axis\n",
    "    r = df.columns\n",
    "\n",
    "    # Names of group and bar width\n",
    "    names = df.columns\n",
    "    barWidth = 1\n",
    "\n",
    "    yold=df.loc[df.index[0]]*0\n",
    "    for c in order:#[c for c in df.index if 'sum' not in c]:\n",
    "        y=df.loc[c]\n",
    "        ax.bar(r, y, bottom=yold, edgecolor='white', color=colors_dict[c],width=barWidth,label=c)\n",
    "        yold=yold+y.copy()\n",
    "\n",
    "    # Custom X axis\n",
    "    ax.set_xticks(r)\n",
    "    ax.set_xlabel(\"clone id\")\n",
    "    ax.set_xticklabels(names.tolist(), rotation = 90)\n",
    "    if k==3:\n",
    "        ax.legend(title='louvain',loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "    ax.set_ylabel('proportion of cells')\n",
    "    \n",
    "    ax.set_title(t)\n",
    "\n",
    "    ax2 = ax.twinx() \n",
    "    ax2.plot(r,dfin2.loc['sum'],'white',linewidth=3)\n",
    "    ax2.set_ylabel('number fo cells',color='gray') \n",
    "    \n",
    "    \n",
    "    #compute metric\n",
    "    #compute average correlation between the most abundant louvain and the rest\n",
    "    df2=gbdfraw.copy()\n",
    "    for c in df2.columns:\n",
    "\n",
    "        dfaux=df2[[c]].loc[df2[c]>0]\n",
    "        \n",
    "        if len(dfaux)>0:\n",
    "\n",
    "            most_abundant=int(dfaux.loc[dfaux[c]==max(dfaux[c])].index.values[0])\n",
    "\n",
    "            dfaux['wcorr']=[adata.uns['dendrogram_'+clustering]['correlation_matrix'][most_abundant,int(i)]*dfaux.loc[i,c] for i in dfaux.index]\n",
    "\n",
    "            #avg correl\n",
    "            suma=dfaux.sum()\n",
    "\n",
    "            avcorrel=suma['wcorr']/suma[c]\n",
    "        else:\n",
    "            dfaux['wcorr']=0\n",
    "            avcorrel=0\n",
    "\n",
    "        #print(avcorrel)\n",
    "    \n",
    "    \n",
    "    k=k+1\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"figuresNEW/\"+cellline+'/prop_cells_perclone'+cellline+\".pdf\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timepoint\n",
    "df=scrna.andata2df(adata)\n",
    "\n",
    "gbdf=df[['Barcode',clustering,'timepoint']].groupby([clustering,'timepoint']).count()\n",
    "gbdf=gbdf.reset_index()\n",
    "gbdf=gbdf.pivot(index=clustering, columns='timepoint', values='Barcode')\n",
    "\n",
    "#discard barcodes with no asigned clone\n",
    "#gbdf=gbdf[[i for i in gbdf.columns if '-' not in i]]\n",
    "\n",
    "#discard clones with no asigned barcodes\n",
    "#gbdf=gbdf[[c for c in gbdf.columns if gbdf[c].sum()>0]]\n",
    "\n",
    "#discard louvains with no barcodes in them\n",
    "#gbdf=gbdf.loc[[c for c in gbdf.index if gbdf.loc[c].sum()>0]]\n",
    "\n",
    "#normalize by louvain\n",
    "gbdf=gbdf.T\n",
    "prop_cellsraw=gbdf.copy()\n",
    "gbdf=gbdf/gbdf.sum()\n",
    "gbdf=gbdf.dropna(axis=1)\n",
    "\n",
    "prop_cells=gbdf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "default_cycler = (cycler(color=['purple','orangered','gold','turquoise']) +\n",
    "                  cycler(linestyle=['-', '--', ':', '-.']))\n",
    "plt.rc('lines', linewidth=4)\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "\n",
    "df=prop_cellsraw.copy()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "# The position of the bars on the x-axis\n",
    "r = df.columns\n",
    "\n",
    "# Names of group and bar width\n",
    "names = df.columns\n",
    "barWidth = 1\n",
    "\n",
    "# Create brown bars\n",
    "#for c in df.index:\n",
    "#    y=df.loc[c]\n",
    "#    ax.bar(r, y, edgecolor='white', width=barWidth,label=c)\n",
    "\n",
    "y_offset=0\n",
    "colors_dict={'0hr':'purple','14day':'orangered','16day':'gold','24r':'turquoise'}\n",
    "for row in range(len(df.index)):\n",
    "    index=df.iloc[row].index\n",
    "    plt.bar(index, df.iloc[row], barWidth, bottom=y_offset,label=df.iloc[[row]].index[0])#,color=colors_dict[index])\n",
    "    y_offset = y_offset + df.iloc[row]\n",
    "    \n",
    "# Custom X axis\n",
    "ax.set_xticks(r)\n",
    "ax.set_xlabel(clustering)\n",
    "ax.set_ylabel(\"number of cells\")\n",
    "ax.set_xticklabels(names.tolist(), rotation = 0)\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig(\"figuresNEW/\"+cellline+'/number_cell_pertimepoint-louvain'+cellline+\".pdf\",bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each clone, look at its proportion in each louvain at each timepoint. Using this info we can score transitions between louvain clusters\n",
    "\n",
    "\n",
    "adata2 = adata[['-' not in i for i in adata.obs['cloneid']]]\n",
    "\n",
    "#,\n",
    "#                data=np.zeros([len(adata2.obs['louvain'].unique()),4]))\n",
    "\n",
    "clones=adata2.obs['cloneid'].unique()\n",
    "\n",
    "dfnorm_dict={c:[] for c in clones}\n",
    "df_dict={c:[] for c in clones}\n",
    "for c in clones:\n",
    "    \n",
    "    df=pd.DataFrame(index=adata2.obs['louvain'].unique().sort_values(),columns=['0hr','24hr','14day','16day'])\n",
    "    \n",
    "    adata3= adata2[adata2.obs['cloneid']==c]\n",
    "    \n",
    "    dff=scrna.andata2df(adata3)\n",
    "    dff=dff[['timepoint','Barcode','louvain']].groupby(['timepoint','louvain']).count().reset_index()\n",
    "\n",
    "    dff=dff.pivot(index='louvain', columns='timepoint', values='Barcode')#[['0hr','24hr','14day','16day']]\n",
    "    \n",
    "    df=df.combine_first(dff)\n",
    "    df=df.fillna(0)\n",
    "    \n",
    "    df=df.loc[adata2.obs['louvain'].unique().sort_values(),['0hr','24hr','14day','16day']]\n",
    "    \n",
    "\n",
    "    df_dict[c]=df\n",
    "    \n",
    "    dfaux=df/df.sum()\n",
    "    dfnorm_dict[c]=dfaux.fillna(0)\n",
    "    \n",
    "    #fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    #sns.heatmap(df/df.sum(),ax=ax)\n",
    "    #sns.heatmap(df,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with index=clones, columns=[louvain0hr,louvain24hr,louvain14day,louvain16day]\n",
    "k=0\n",
    "for c,df in dfnorm_dict.items():\n",
    "    df['louvain']=df.index\n",
    "    df=df.melt(id_vars=['louvain'])\n",
    "    df['louvain_time']=df['louvain'].astype(str)+'_'+df['variable']\n",
    "    df.index=df['louvain_time']\n",
    "    df=df[['value']]\n",
    "    df=df.T\n",
    "    df['cloneid']=c\n",
    "    if k==0:\n",
    "        dfcoord=df.copy()\n",
    "    else:\n",
    "        dfcoord=dfcoord.append(df,ignore_index=True)\n",
    "    k=k+1\n",
    "    \n",
    "dfcoord.index=dfcoord['cloneid']\n",
    "dfcoord=dfcoord[[c for c in dfcoord.columns if 'cloneid' not in c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=sns.clustermap(dfcoord,col_cluster=False,z_score=0,cbar_kws={'label': 'z_score'})\n",
    "fig = plot.fig\n",
    "fig.savefig(\"figuresNEW/\"+cellline+'/heatmap_cell_prop'+cellline+\".pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_kmeans(df,n_clusters=4):\n",
    "\n",
    "    import sklearn.cluster as cluster\n",
    "    import seaborn as sns\n",
    "\n",
    "    features=[i for i in df.columns if '_' in i]\n",
    "    X = df.loc[:,features]\n",
    "\n",
    "    #clustering = cluster.KMeans(n_clusters=n_clusters)#.AffinityPropagation()#n_clusters=n_clusters)#\n",
    "    clustering = cluster.SpectralClustering(n_clusters=n_clusters)#.AffinityPropagation()#n_clusters=n_clusters)#\n",
    "    \n",
    "    clustering.fit(X)\n",
    "\n",
    "    df2=df.copy()\n",
    "    df2['clustering']=[str(i) for i in clustering.labels_]\n",
    "    \n",
    "    #sns.lmplot(data=df2,x='PC1',y='PC2',hue='clustering',fit_reg=False)\n",
    "    #for i in range(len(df)):\n",
    "    #    plt.text(df2.iloc[i]['PC1'],df2.iloc[i]['PC2'],str(i))\n",
    "    #plt.show()\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#feats=[c for c in dfcoord.columns if '_' in c]\n",
    "#dfcoord,load = do_pca(dfcoord,feats,Npca=5,number_genes=[],zscore=True)\n",
    "min_number_cells=100 #minimum number of cells per traj class to determine number of traj classes\n",
    "\n",
    "\n",
    "nclust=8\n",
    "done=False\n",
    "while done==False:\n",
    "    dfcoord=add_kmeans(dfcoord,n_clusters=nclust)\n",
    "\n",
    "    diction={i:dfcoord['clustering'].loc[i] for i in dfcoord.index}\n",
    "    s1=adata2.obs['cloneid']\n",
    "    s1=s1.map(diction)\n",
    "    adata2.obs['trajectory_class']=s1\n",
    "    adata2.obs['trajectory_class']=adata2.obs['trajectory_class'].replace(np.nan,'-')\n",
    "\n",
    "    df=scrna.andata2df(adata2)\n",
    "    df=df[['trajectory_class','Barcode']].groupby(['trajectory_class']).count().reset_index()\n",
    "    lista=df['Barcode']\n",
    "    done=all(i >= min_number_cells for i in lista)\n",
    "    \n",
    "    nclust=nclust-1\n",
    "    \n",
    "nclust=nclust+1\n",
    "print('optimal number of clusters',nclust)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feats=[c for c in dfcoord.columns if '_' in c]\n",
    "#dfcoord,load = do_pca(dfcoord,feats,Npca=5,number_genes=[],zscore=True)\n",
    "min_number_clones=2 #minimum number of clones per traj class and timepoint to determine number of traj classes\n",
    "\n",
    "\n",
    "nclust=8\n",
    "done=False\n",
    "while done==False:\n",
    "    dfcoord=add_kmeans(dfcoord,n_clusters=nclust)\n",
    "\n",
    "    diction={i:dfcoord['clustering'].loc[i] for i in dfcoord.index}\n",
    "    s1=adata2.obs['cloneid']\n",
    "    s1=s1.map(diction)\n",
    "    adata2.obs['trajectory_class']=s1\n",
    "    adata2.obs['trajectory_class']=adata2.obs['trajectory_class'].replace(np.nan,'-')\n",
    "\n",
    "    df=scrna.andata2df(adata2)\n",
    "    df=df[['trajectory_class','timepoint','cloneid']].groupby(['trajectory_class','timepoint']).nunique().reset_index()\n",
    "    lista=df['cloneid']\n",
    "    done=all(i >= min_number_clones for i in lista)\n",
    "    \n",
    "    nclust=nclust-1\n",
    "    \n",
    "nclust=nclust+1\n",
    "print('optimal number of clusters',nclust)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=scrna.andata2df(adata2)\n",
    "df.loc[df['trajectory_class']=='2']['cloneid'].values.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adataaux=adata2[adata2.obs['trajectory_class']=='0']\n",
    "sc.pl.umap(adataaux,color=['timepoint'],size=10)\n",
    "\n",
    "sc.pl.umap(adataaux,color=['cloneid'],size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nclust=5\n",
    "dfcoord=add_kmeans(dfcoord,n_clusters=nclust)\n",
    "\n",
    "diction={i:dfcoord['clustering'].loc[i] for i in dfcoord.index}\n",
    "s1=adata2.obs['cloneid']\n",
    "s1=s1.map(diction)\n",
    "adata2.obs['trajectory_class']=s1\n",
    "adata2.obs['trajectory_class']=adata2.obs['trajectory_class'].replace(np.nan,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add trajectory type into the andata file\n",
    "diction={i:dfcoord['clustering'].loc[i] for i in dfcoord.index}\n",
    "s1=adata.obs['cloneid']\n",
    "s1=s1.map(diction)\n",
    "adata.obs['trajectory_class']=s1\n",
    "adata.obs['trajectory_class']=adata.obs['trajectory_class'].replace(np.nan,'-')\n",
    "\n",
    "\n",
    "diction={i:dfcoord['clustering'].loc[i] for i in dfcoord.index}\n",
    "s1=adata2.obs['cloneid']\n",
    "s1=s1.map(diction)\n",
    "adata2.obs['trajectory_class']=s1\n",
    "adata2.obs['trajectory_class']=adata2.obs['trajectory_class'].replace(np.nan,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(14, 10))\n",
    "ax=ax.ravel()\n",
    "kk=0\n",
    "for tc in adata2.obs['trajectory_class'].unique():\n",
    "    axs=ax[kk]\n",
    "    adataaux=adata2[adata2.obs['trajectory_class']==tc]\n",
    "    dff=scrna.andata2df(adata2)\n",
    "    #axs.scatter(dff['UMAP1'],dff['UMAP2'],color='lightgray',alpha=0.3)\n",
    "    \n",
    "    \n",
    "    stratify='timepoint'\n",
    "    feat='UMAP'\n",
    "    colors = ['purple','orangered','gold','turquoise']#['darkred','violet','green','b']\n",
    "    xs = feat + '1'\n",
    "    ys = feat + '2'\n",
    "    expr = scrna.andata2df(adataaux)\n",
    "    expr=expr.sort_values(stratify)\n",
    "    axw = axs\n",
    "    for c, color in zip(expr[stratify].unique(), colors):  # print cell type text\n",
    "        mask = expr[stratify] == c\n",
    "        expraux = expr.loc[mask, [xs, ys, stratify]]\n",
    "        axw.scatter(expraux[xs], expraux[ys], c=color, edgecolor='lightgray', s=80, marker='.', label=c,\n",
    "                    linewidths=.3,alpha=0.5)\n",
    "        xav = np.mean(expraux[xs])\n",
    "        yav = np.mean(expraux[ys])\n",
    "        ctype = expraux[stratify].values[0]\n",
    "\n",
    "    axw.set_xlabel(xs)\n",
    "    axw.set_ylabel(ys)\n",
    "\n",
    "\n",
    "    axs.set_xticks([])\n",
    "    \n",
    "    axw.legend()\n",
    "    \n",
    "\n",
    "    scv.pl.scatter(adata2, color='louvain', size=80,ax=axs,add_outline=True,alpha=0,show=False)\n",
    "          \n",
    "    axs.set_title('traj class:'+tc)\n",
    "    #sc.pl.umap(adata,alpha=0.1, s=100,ax=axs)\n",
    "    kk=kk+1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"figuresNEW/\"+cellline+\"/UMAPS_final/\"+cellline+\"traj_classesUMAP.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write('final_anndatasNEW/'+cellline+'.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLENTY.v2022.1",
   "language": "python",
   "name": "plenty.v2022.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
